# -*- coding: utf-8 -*-
"""DecissionTree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-fUJJqafN1aZ4sMlO-WYtZwq3FPpA6oy
"""

from google.colab import files
uploaded = files.upload()  # Click 'Choose File' and select the 'train.csv' file from your extracted folder.

# --- IMPORT LIBRARIES ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("‚úÖ All libraries imported!")

df = pd.read_csv('train.csv')

print("üìä First look at the data:")
print(df.head())
print("\nüîç Dataset Info:")
print(df.info())
print("\n‚ùå Checking for missing values:")
print(df.isnull().sum())

# Handle missing values - The Correct Way
df = df.assign(
    Age=df['Age'].fillna(df['Age'].median()),
    Embarked=df['Embarked'].fillna('S')
)

# Drop columns that are not useful for a simple model
# Cabin: Too many missing values
# Name, Ticket, PassengerId: Not predictive for survival
df_clean = df.drop(['Cabin', 'Name', 'Ticket', 'PassengerId'], axis=1)

print("\n‚úÖ Cleaning complete! Remaining missing values:")
print(df_clean.isnull().sum())

# --- CONVERT TEXT TO NUMBERS ---
# Convert 'Sex' to a number (male=0, female=1)
df_clean['Sex'] = df_clean['Sex'].map({'male': 0, 'female': 1})

# Convert 'Embarked' to a number (C=0, Q=1, S=2)
df_clean['Embarked'] = df_clean['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})

print("\nüî¢ Data after converting text to numbers:")
print(df_clean.head())

# --- PREPARE DATA FOR MODEL ---
# X: Features (all columns except 'Survived')
X = df_clean.drop('Survived', axis=1)
# y: Target (the column we want to predict)
y = df_clean['Survived']

# Split data into 80% training set, 20% testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"\nüìà Data split for training:")

print(f"\nüìà Data split for training:")
print(f"Training Features: {X_train.shape}")
print(f"Training Target: {y_train.shape}")
print(f"Testing Features: {X_test.shape}")
print(f"Testing Target: {y_test.shape}")

# --- CREATE AND TRAIN THE MODEL ---
# Create a Decision Tree classifier. max_depth=3 keeps it simple and readable.
model = tree.DecisionTreeClassifier(max_depth=3, random_state=42)
# Train the model on the training data
model.fit(X_train, y_train)

print("\nü§ñ Model trained successfully!")

# --- MAKE PREDICTIONS AND EVALUATE ---
# Use the model to predict on the test set
predictions = model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, predictions)
print(f"\nüéØ Model Accuracy: {accuracy:.3f} ({accuracy * 100:.1f}%)")

# Show a detailed performance report
print("\nüìù Detailed Classification Report:")
print(classification_report(y_test, predictions))

# Plot a confusion matrix
print("\nüß© Confusion Matrix:")
cm = confusion_matrix(y_test, predictions)
plt.figure(figsize=(7,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Predicted Died', 'Predicted Survived'],
            yticklabels=['Actually Died', 'Actually Survived'])
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# --- VISUALIZE THE DECISION TREE ---
print("\nüå≥ Visualizing the Decision Tree:")
plt.figure(figsize=(20,12))
tree.plot_tree(model,
               feature_names=X.columns,
               class_names=['Died', 'Survived'],
               filled=True,
               rounded=True,
               impurity=False,
               precision=1,
               fontsize=12)
plt.show()

# --- BONUS: FEATURE IMPORTANCE ---
# See which features were most important for the model's decisions
print("\ÔøΩÔ∏è Most Important Features for Predicting Survival:")
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_importance)

